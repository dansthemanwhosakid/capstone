{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 4B: Doc2Vec Recommender\n",
    "\n",
    "I will create a character recommendation system by using gensim's Doc2Vec model to calculate the similarity between one chosen character's movie lines to other characters' movie lines. The final result will be a function that allows a user to input a movie character's name, and it will return the top 10 most similar characters.\n",
    "\n",
    "\n",
    "[**Doc2Vec Process**](https://medium.com/scaleabout/a-gentle-introduction-to-doc2vec-db3e8c0cce5e)\n",
    "\n",
    "Doc2Vec is a neural network that utilizes Word2Vec and a paragraph matrix (aka document vector). In essence, it uses Word2Vec's two algorithms, continuous bag of words (CBOW) and skim gram. The CBOW is an algorithm that scans the context of surrounding words in a text to predict a word, whereas the skip gram uses a single word to predict the context of all surrounding words. Word2Vec will be used to predict the concept of a word, and Doc2Vec acts as a memory that is trained to represent the concept/topic of a document.\n",
    "\n",
    "\n",
    "![alt text](../photos/doc2vec_graph.png \"Title\")\n",
    "\n",
    "\n",
    "In our particular case, each character's total movie lines will be synonymous to a document. Based on the `mov_model` dataframe, there are 76127 documents (movie lines) that need to be processed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "mov_model = pd.read_pickle(\"../data/mov_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 76127 movie characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76127"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mov_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>character</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bartender</td>\n",
       "      <td>What can I get you You forgot to pay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bianca</td>\n",
       "      <td>Did you change your hair You might wanna think...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bianca and walter</td>\n",
       "      <td>The sound of a fifteen year old in labor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           character                                         clean_text\n",
       "0          bartender              What can I get you You forgot to pay \n",
       "1             bianca  Did you change your hair You might wanna think...\n",
       "2  bianca and walter          The sound of a fifteen year old in labor "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mov_model[['character','clean_text']].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing the `clean_text` values to be all lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "mov_model['clean_text'] = mov_model['clean_text'].map(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will now combine and group the documents and tag them for identification purposes. It is not conducive to tag the documents based on the character names because many movie characters share the same name, so filtering will be a nightmare. Instead, each character in the `mov_model` dataframe can be identified by its unique id that ranges from 0 to 76127. As a result, I will tag each of their move lines by their unique id as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_docs = list(df['clean_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_docs = [TaggedDocument(words = word_tokenize(doc.lower()), tags = [str(pos)]) for pos, doc in enumerate(all_docs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of examining the bartender's `clean_text` and `tagged_data` by using its unique id 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'what can i get you you forgot to pay '"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mov_model.at[0,'clean_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaggedDocument(words=['what', 'can', 'i', 'get', 'you', 'you', 'forgot', 'to', 'pay'], tags=['0'])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_docs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Doc2Vec NN Model\n",
    "The Doc2Vec is a neural network with a single projection and a hidden layer that is used to train on the corpus, which is all of the combined documents. The inputs of the model consist of two vectors: the word vectors of each word in each document and the paragraph vector. \n",
    "\n",
    "The following code is altered from [medium](https://medium.com/@mishra.thedeepak/doc2vec-simple-implementation-example-df2afbbfbad5).\n",
    "\n",
    "Gensim's Doc2Vec model has several parameters that can be modified/trained:\n",
    "\n",
    "`size` = 150\n",
    "   - A size of 150 means that each document's vector will contain 150 elements, so each document will occupy a point in a 150 dimensional space. A higher size implies that there are more dimensions, which allows for more differentiation between documents.\n",
    "   \n",
    "`alpha` = 0.025\n",
    "- The alpha is the initial learning rate which is to minimize the loss function. \n",
    "\n",
    "`min_count` = 2\n",
    "- Ignores all words with total frequency lower than 2\n",
    "\n",
    "`dm` = 1\n",
    "- DM = 1 means that the Distributed Memory version of Paragraph Vector (PV-DM) will be used to for the training algorithm. Essentially, it acts as a memory that remembers what is missing from the the current context of a character's movie line. \n",
    "\n",
    "`max_epochs` = 100\n",
    "- 100 epochs mean that all the tagged documents pass through the neural network 100 times in order to optimize the learning by using gradient descent to decrease the loss function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing epoch number: 0\n",
      "Processing epoch number: 5\n",
      "Processing epoch number: 10\n",
      "Processing epoch number: 15\n",
      "Processing epoch number: 20\n",
      "Processing epoch number: 25\n",
      "Processing epoch number: 30\n",
      "Processing epoch number: 35\n",
      "Processing epoch number: 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:18: DeprecationWarning: Call to deprecated `iter` (Attribute will be removed in 4.0.0, use self.epochs instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing epoch number: 45\n",
      "Processing epoch number: 50\n",
      "Processing epoch number: 55\n",
      "Processing epoch number: 60\n",
      "Processing epoch number: 65\n",
      "Processing epoch number: 70\n",
      "Processing epoch number: 75\n",
      "Processing epoch number: 80\n",
      "Processing epoch number: 85\n",
      "Processing epoch number: 90\n",
      "Processing epoch number: 95\n",
      "Model Saved\n"
     ]
    }
   ],
   "source": [
    "model = Doc2Vec(vector_size = 150,\n",
    "                alpha = 0.025, \n",
    "                min_alpha = 0.00025,\n",
    "                min_count = 2,\n",
    "                dm = 1)\n",
    "\n",
    "# Builds the vocabulary from all of the documents\n",
    "model.build_vocab(tagged_docs)\n",
    "\n",
    "max_epochs = 100\n",
    "\n",
    "for epoch in range(max_epochs):    \n",
    "    if epoch % 5 == 0:\n",
    "        print(f'Processing epoch number: {epoch}')\n",
    "        \n",
    "    model.train(tagged_data,\n",
    "                total_examples=model.corpus_count,\n",
    "                epochs=model.iter)\n",
    "    \n",
    "    # decrease the learning rate\n",
    "    model.alpha -= 0.0002\n",
    "    # fix the learning rate, no decay\n",
    "    model.min_alpha = model.alpha\n",
    "\n",
    "model.save(\"../models/d2v.model\")\n",
    "print(\"Model Saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Character Similarity\n",
    "With the saved model, I will now examine the top 10 similar characters based on Doc2Vec's [most_similar()](https://radimrehurek.com/gensim/models/keyedvectors.html#gensim.models.keyedvectors.Doc2VecKeyedVectors.most_similar) function. The most_similar() function computes cosine similarity between a simple mean of the projection weight vectors of the given docs. I am going to use the bartender from 10 Things I Hate About You (1999) as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "imdb_title         10 Things I Hate About You (1999)\n",
       "character                                  bartender\n",
       "text          What can I get you? You forgot to pay!\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mov_model.loc[0,['imdb_title','character','text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(28619, 0.32750070095062256),\n",
       " (30941, 0.31470227241516113),\n",
       " (54820, 0.301654577255249),\n",
       " (56930, 0.2961265742778778),\n",
       " (14410, 0.29411712288856506),\n",
       " (64972, 0.29212257266044617),\n",
       " (67517, 0.29112035036087036),\n",
       " (21364, 0.2874348759651184),\n",
       " (12569, 0.2868254482746124),\n",
       " (58117, 0.28625547885894775)]"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.docvecs.most_similar(0, topn = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function returns the top 10 most similar characters. The first number of each tuple is each character's unique id, and the second number is the character's cosine similarity. I will now investigate character 30941's movie lines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "imdb_title                                      I Am Sam (2001)\n",
       "character                                               bailiff\n",
       "text          ...the whole truth, and nothing but the truth,...\n",
       "Name: 30941, dtype: object"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mov_model.loc[30941,['imdb_title','character','text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'...the whole truth, and nothing but the truth, so help you God?'"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mov_model.loc[30941,'text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the short sentences of each movie character, it is hard to determine how exactly 'similar' these characters are. With the saved Doc2Vec model, I will now create a character recommendation function where it will allow the user to filter for characters by toggling genres, movies, and other parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proceed to Notebook 5: Character Recommendation Function"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
